{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "from open_patstat.utils.gcp import create_table, load_gcs_file, delete_table\n",
    "from open_patstat.utils.schema import Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Client anf Job Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this line, make sure that you have defined the environment variable...\n",
    "# ...\"GOOGLE_APPLICATION_CREDENTIALS\" which points to the JSON file containing authentication key\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Job_config\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.max_bad_records = 10\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "dataset_ref = client.dataset('patstat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Adding Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS TABLE ALREADY EXISTS IN usptobias:patstat\n"
     ]
    }
   ],
   "source": [
    "########## Creating and Loading tables ##########\n",
    "#################################################\n",
    "\n",
    "# Tables list to be loaded\n",
    "tables_list = ['tls212']\n",
    "\n",
    "# Google Bucket directory address, which contains all data files\n",
    "gs_add = 'gs://patstat_2018g/data_PATSTAT_Global_2018_Autumn/'\n",
    "\n",
    "# Loading the tables in the list\n",
    "for table in tables_list:\n",
    "    # Creating the table\n",
    "    create_table(client,\n",
    "             dataset_id='patstat',\n",
    "             table_id=table,\n",
    "             schema=getattr(Schema(),table))\n",
    "    # Adding files to the table from GCP bucket\n",
    "    table_ref = dataset_ref.table(table)\n",
    "    job_config.schema = getattr(Schema(),table)\n",
    "    load_job = client.load_table_from_uri(\n",
    "        source_uris=gs_add+table+'_*.gz',\n",
    "        destination=table_ref,\n",
    "        # job_id=job_id,\n",
    "        job_id_prefix='lgs-',\n",
    "        job_config=job_config,\n",
    "    )\n",
    "    load_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating \"familyInfo\" table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "\n",
    "# Initializing the Job_config\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.max_bad_records = 10\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "dataset_ref = client.dataset('results_docdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Schema' object has no attribute 'familyInformation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3ece4f0df334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m              \u001b[0mdataset_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'patstat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m              \u001b[0mtable_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m              schema=getattr(Schema(),table))\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Adding files to the table from GCP bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtable_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Schema' object has no attribute 'familyInformation'"
     ]
    }
   ],
   "source": [
    "########## Creating and Loading tables ##########\n",
    "#################################################\n",
    "\n",
    "# Tables list to be loaded\n",
    "tables_list = ['familyInformation']\n",
    "\n",
    "# Google Bucket directory address, which contains all data files\n",
    "gs_add = 'gs://family_Information/'\n",
    "\n",
    "# Loading the tables in the list\n",
    "for table in tables_list:\n",
    "    # Creating the table\n",
    "    create_table(client,\n",
    "             dataset_id='patstat',\n",
    "             table_id=table,\n",
    "             schema=getattr(Schema(),table))\n",
    "    # Adding files to the table from GCP bucket\n",
    "    table_ref = dataset_ref.table(table)\n",
    "    job_config.schema = getattr(Schema(),table)\n",
    "    load_job = client.load_table_from_uri(\n",
    "        source_uris=gs_add+table+'_*.gz',\n",
    "        destination=table_ref,\n",
    "        # job_id=job_id,\n",
    "        job_id_prefix='lgs-',\n",
    "        job_config=job_config,\n",
    "    )\n",
    "    load_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Mapping table for mapping USPTO ID to PatStat ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()\n",
    "# Initializing the Job_config\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.skip_leading_rows = 1\n",
    "job_config.max_bad_records = 10\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "dataset_ref = client.dataset('patstat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS TABLE ALREADY EXISTS IN usptobias:patstat\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 Error while reading data, error message: CSV table encountered too many errors, giving up. Rows: 11; errors: 11. Please look into the errors[] collection for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4a729cbb45db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mjob_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mload_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ip2019/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ip2019/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Error while reading data, error message: CSV table encountered too many errors, giving up. Rows: 11; errors: 11. Please look into the errors[] collection for more details."
     ]
    }
   ],
   "source": [
    "########## Creating and Loading tables ##########\n",
    "#################################################\n",
    "\n",
    "# Tables list to be loaded\n",
    "tables_list = ['mapping']\n",
    "\n",
    "# Google Bucket directory address, which contains all data files\n",
    "gs_add = 'gs://uspto-data/patentsView/'\n",
    "\n",
    "# Loading the tables in the list\n",
    "for table in tables_list:\n",
    "    # Creating the table\n",
    "    create_table(client,\n",
    "             dataset_id='patstat',\n",
    "             table_id=table,\n",
    "             schema=getattr(Schema(),table))\n",
    "    # Adding files to the table from GCP bucket\n",
    "    table_ref = dataset_ref.table(table)\n",
    "    job_config.schema = getattr(Schema(),table)\n",
    "    load_job = client.load_table_from_uri(\n",
    "        source_uris=gs_add+table+'*.gz',\n",
    "        destination=table_ref,\n",
    "        # job_id=job_id,\n",
    "        job_id_prefix='lgs-',\n",
    "        job_config=job_config,\n",
    "    )\n",
    "    load_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'reason': 'invalid',\n",
       "  'location': 'gs://uspto-data/patentsView/mapping.csv.gz',\n",
       "  'message': 'Error while reading data, error message: CSV table encountered too many errors, giving up. Rows: 11; errors: 11. Please look into the errors[] collection for more details.'},\n",
       " {'reason': 'invalid',\n",
       "  'location': 'gs://uspto-data/patentsView/mapping.csv.gz',\n",
       "  'message': \"Error while reading data, error message: Could not parse '51621246.0' as int for field appln_id (position 1) starting at location 19\"},\n",
       " {'reason': 'invalid',\n",
       "  'location': 'gs://uspto-data/patentsView/mapping.csv.gz',\n",
       "  'message': \"Error while reading data, error message: Could not parse '51379297.0' as int for field appln_id (position 1) starting at location 38\"},\n",
       " {'reason': 'invalid',\n",
       "  'location': 'gs://uspto-data/patentsView/mapping.csv.gz',\n",
       "  'message': \"Error while reading data, error message: Could not parse '51677498.0' as int for field appln_id (position 1) starting at location 57\"},\n",
       " {'reason': 'invalid',\n",
       "  'location': 'gs://uspto-data/patentsView/mapping.csv.gz',\n",
       "  'message': \"Error while reading data, error message: Could not parse '51475922.0' as int for field appln_id (position 1) starting at location 76\"},\n",
       " {'reason': 'invalid',\n",
       "  'location': 'gs://uspto-data/patentsView/mapping.csv.gz',\n",
       "  'message': \"Error while reading data, error message: Could not parse '51858978.0' as int for field appln_id (position 1) starting at location 95\"}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_job.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_folder = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
